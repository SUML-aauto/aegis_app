{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\s25025\\desktop\\aegis_app\\.venv\\lib\\site-packages (1.6.0)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\s25025\\desktop\\aegis_app\\.venv\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\s25025\\desktop\\aegis_app\\.venv\\lib\\site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\s25025\\desktop\\aegis_app\\.venv\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\s25025\\desktop\\aegis_app\\.venv\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\s25025\\desktop\\aegis_app\\.venv\\lib\\site-packages (2.2.3)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\s25025\\desktop\\aegis_app\\.venv\\lib\\site-packages (from pandas) (2.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\s25025\\desktop\\aegis_app\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\s25025\\desktop\\aegis_app\\.venv\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\s25025\\desktop\\aegis_app\\.venv\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\s25025\\desktop\\aegis_app\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Collecting skops\n",
      "  Downloading skops-0.11.0-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting huggingface-hub>=0.17.0 (from skops)\n",
      "  Downloading huggingface_hub-0.27.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\s25025\\desktop\\aegis_app\\.venv\\lib\\site-packages (from skops) (24.2)\n",
      "Requirement already satisfied: scikit-learn>=1.1 in c:\\users\\s25025\\desktop\\aegis_app\\.venv\\lib\\site-packages (from skops) (1.6.0)\n",
      "Collecting tabulate>=0.8.8 (from skops)\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting filelock (from huggingface-hub>=0.17.0->skops)\n",
      "  Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.17.0->skops)\n",
      "  Downloading fsspec-2024.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting pyyaml>=5.1 (from huggingface-hub>=0.17.0->skops)\n",
      "  Downloading PyYAML-6.0.2-cp312-cp312-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting requests (from huggingface-hub>=0.17.0->skops)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tqdm>=4.42.1 (from huggingface-hub>=0.17.0->skops)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting typing-extensions>=3.7.4.3 (from huggingface-hub>=0.17.0->skops)\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\s25025\\desktop\\aegis_app\\.venv\\lib\\site-packages (from scikit-learn>=1.1->skops) (2.2.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\s25025\\desktop\\aegis_app\\.venv\\lib\\site-packages (from scikit-learn>=1.1->skops) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\s25025\\desktop\\aegis_app\\.venv\\lib\\site-packages (from scikit-learn>=1.1->skops) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\s25025\\desktop\\aegis_app\\.venv\\lib\\site-packages (from scikit-learn>=1.1->skops) (3.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\s25025\\desktop\\aegis_app\\.venv\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.17.0->skops) (0.4.6)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->huggingface-hub>=0.17.0->skops)\n",
      "  Downloading charset_normalizer-3.4.0-cp312-cp312-win_amd64.whl.metadata (34 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->huggingface-hub>=0.17.0->skops)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->huggingface-hub>=0.17.0->skops)\n",
      "  Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->huggingface-hub>=0.17.0->skops)\n",
      "  Downloading certifi-2024.12.14-py3-none-any.whl.metadata (2.3 kB)\n",
      "Downloading skops-0.11.0-py3-none-any.whl (146 kB)\n",
      "Downloading huggingface_hub-0.27.0-py3-none-any.whl (450 kB)\n",
      "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Downloading fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
      "Downloading PyYAML-6.0.2-cp312-cp312-win_amd64.whl (156 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading certifi-2024.12.14-py3-none-any.whl (164 kB)\n",
      "Downloading charset_normalizer-3.4.0-cp312-cp312-win_amd64.whl (102 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Installing collected packages: urllib3, typing-extensions, tqdm, tabulate, pyyaml, idna, fsspec, filelock, charset-normalizer, certifi, requests, huggingface-hub, skops\n",
      "Successfully installed certifi-2024.12.14 charset-normalizer-3.4.0 filelock-3.16.1 fsspec-2024.10.0 huggingface-hub-0.27.0 idna-3.10 pyyaml-6.0.2 requests-2.32.3 skops-0.11.0 tabulate-0.9.0 tqdm-4.67.1 typing-extensions-4.12.2 urllib3-2.2.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn\n",
    "%pip install pandas\n",
    "%pip install skops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import skops.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s25025\\Desktop\\aegis_app\\.venv\\Lib\\site-packages\\sklearn\\impute\\_base.py:635: UserWarning: Skipping features without any observed values: ['Make']. At least one non-missing value is needed for imputation with strategy='most_frequent'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\s25025\\Desktop\\aegis_app\\.venv\\Lib\\site-packages\\sklearn\\impute\\_base.py:635: UserWarning: Skipping features without any observed values: ['Make']. At least one non-missing value is needed for imputation with strategy='most_frequent'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liability Insurance - MSE: 427.42, RMSE: 20.67, Average Difference (Predicted - Real): -1.17\n",
      "Theft Insurance - MSE: 59.42, RMSE: 7.71, Average Difference (Predicted - Real): 0.10\n",
      "Premium Insurance - MSE: 46.51, RMSE: 6.82, Average Difference (Predicted - Real): 0.18\n",
      "Repair Insurance - MSE: 41.43, RMSE: 6.44, Average Difference (Predicted - Real): -0.09\n",
      "Premium Repair Insurance - MSE: 148.79, RMSE: 12.20, Average Difference (Predicted - Real): -0.29\n"
     ]
    }
   ],
   "source": [
    "file_path = 'data_set.csv'\n",
    "data = pd.read_csv(file_path, delimiter=';', on_bad_lines='skip')\n",
    "\n",
    "features = ['Make', 'Model', 'Engine Power (HP)', 'Mileage (km)', 'Number of Accidents', 'Market Value ($)',\n",
    "            'Total Owners', 'Has Dashcam', 'Vehicles in Family', 'Driving Experience', 'CAR_AGE',\n",
    "            'AGE', 'HOMEKIDS', 'INCOME']\n",
    "insurance_types = ['Liability Insurance', 'Theft Insurance', 'Premium Insurance', 'Repair Insurance',\n",
    "                   'Premium Repair Insurance']\n",
    "\n",
    "if data['Has Dashcam'].dtype == 'object':\n",
    "    data['Has Dashcam'] = data['Has Dashcam'].str.strip().str.lower().map({'true': 1, 'false': 0})\n",
    "\n",
    "for col in features + insurance_types:\n",
    "    if col in data.columns and data[col].dtype == 'object':\n",
    "        data[col] = data[col].str.replace(',', '.').str.replace('[^0-9.]', '', regex=True)\n",
    "        data[col] = pd.to_numeric(data[col], errors='coerce')\n",
    "\n",
    "numeric_features = [col for col in features if col not in ['Make', 'Model']]\n",
    "categorical_features = ['Make', 'Model']\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "X = data[features]\n",
    "\n",
    "preprocessor.fit(X)\n",
    "\n",
    "preprocessed_X = preprocessor.transform(X)\n",
    "\n",
    "results = {}\n",
    "models = {}\n",
    "for insurance in insurance_types:\n",
    "    y = data[insurance]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(preprocessed_X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    model = GradientBoostingRegressor(random_state=42, n_estimators=300, learning_rate=0.03, max_depth=7)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    models[insurance] = model\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_clipped = np.clip(y_pred, y.min(), y.max())\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred_clipped)\n",
    "    rmse = np.sqrt(mse)\n",
    "    avg_diff = np.mean(y_pred_clipped - y_test)\n",
    "\n",
    "    results[insurance] = {\n",
    "        'MSE': mse,\n",
    "        'RMSE': rmse,\n",
    "        'Average Difference (Predicted - Real)': avg_diff\n",
    "    }\n",
    "\n",
    "models['preprocessor'] = preprocessor\n",
    "\n",
    "for insurance, metrics in results.items():\n",
    "    print(\n",
    "        f\"{insurance} - MSE: {metrics['MSE']:.2f}, RMSE: {metrics['RMSE']:.2f}, Average Difference (Predicted - Real): {metrics['Average Difference (Predicted - Real)']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sio.dump(models, 'model2.skops')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocessor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 19\u001b[0m\n\u001b[0;32m      1\u001b[0m single_entity \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMake\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHonda\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCivic\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mINCOME\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m67349\u001b[39m\n\u001b[0;32m     16\u001b[0m }\n\u001b[0;32m     18\u001b[0m single_entity_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([single_entity])\n\u001b[1;32m---> 19\u001b[0m single_entity_preprocessed \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocessor\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(single_entity_df)\n\u001b[0;32m     21\u001b[0m single_entity_predictions \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m insurance \u001b[38;5;129;01min\u001b[39;00m insurance_types:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'preprocessor' is not defined"
     ]
    }
   ],
   "source": [
    "single_entity = {\n",
    "    'Make': 'Honda',\n",
    "    'Model': 'Civic',\n",
    "    'Engine Power (HP)': 202,\n",
    "    'Mileage (km)': 40594,\n",
    "    'Number of Accidents': 0,\n",
    "    'Market Value ($)': 21440,\n",
    "    'Total Owners': 1,\n",
    "    'Has Dashcam': 1,\n",
    "    'Vehicles in Family': 4,\n",
    "    'Driving Experience': 3,\n",
    "    'CAR_AGE': 18,\n",
    "    'AGE': 60,\n",
    "    'HOMEKIDS': 0,\n",
    "    'INCOME': 67349\n",
    "}\n",
    "\n",
    "single_entity_df = pd.DataFrame([single_entity])\n",
    "single_entity_preprocessed = preprocessor.transform(single_entity_df)\n",
    "\n",
    "single_entity_predictions = {}\n",
    "for insurance in insurance_types:\n",
    "    y = data[insurance]\n",
    "    model = GradientBoostingRegressor(random_state=42, n_estimators=300, learning_rate=0.03, max_depth=7)\n",
    "    model.fit(preprocessed_X, y)\n",
    "\n",
    "    predicted_price = np.clip(model.predict(single_entity_preprocessed)[0], y.min(), y.max())\n",
    "    single_entity_predictions[insurance] = predicted_price\n",
    "\n",
    "print(\"Predicted Insurance Prices for Single Entity:\")\n",
    "for insurance, price in single_entity_predictions.items():\n",
    "    print(f\"{insurance}: {price:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'insurance_types' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m single_entity_predictions \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m insurance \u001b[38;5;129;01min\u001b[39;00m \u001b[43minsurance_types\u001b[49m:\n\u001b[0;32m      4\u001b[0m     y \u001b[38;5;241m=\u001b[39m data[insurance]\n\u001b[0;32m      5\u001b[0m     model \u001b[38;5;241m=\u001b[39m GradientBoostingRegressor(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m300\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.03\u001b[39m, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'insurance_types' is not defined"
     ]
    }
   ],
   "source": [
    "single_entity_predictions = {}\n",
    "\n",
    "for insurance in insurance_types:\n",
    "    y = data[insurance]\n",
    "    model = GradientBoostingRegressor(random_state=42, n_estimators=300, learning_rate=0.03, max_depth=7)\n",
    "    model.fit(preprocessed_X, y)\n",
    "\n",
    "    predicted_price = np.clip(model.predict(single_entity_preprocessed)[0], y.min(), y.max())\n",
    "    single_entity_predictions[insurance] = predicted_price\n",
    "\n",
    "print(\"Predicted Insurance Prices for Single Entity:\")\n",
    "for insurance, price in single_entity_predictions.items():\n",
    "    print(f\"{insurance}: {price:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
